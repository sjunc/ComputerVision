# ComputerVision
## 2주차 
### 컴퓨터 비전의 역사, 실습 환경 구성
영상처리(보정)  
컴퓨터 비전(인식)  
### 인간의 시각  
인간의 시각은 오감 중에서 가장 뛰어남(대역폭이 가장 넓음)  
분류, 검출, 분할, 추적, 행동 분석에 능숙함  
3차원 복원 능력이 있음(2차원 인식-3차원 복원)    
빠르고 강건함  
다른 지능 요소인 지식 표현, 추론, 계획과 협동함(의사결정)  
사전 행동(proactive 일이 일어나기 전에 예측)에 능숙함(사후 행동: reactive 일이 일어난 후에 인지)  
과업 전환(Task Switching)이 매끄럽고 유기적이고 빠름  
비주얼 서보잉(Visual Servoing 시각적인 정보를 실시간으로 반영해 움직임을 정밀제어하는 기술)이 뛰어남  
**한계**  
착시가 있음  
정밀 측정에 오차가 있음  
시야가 한정됨    
피로해지고 퇴화함  
### 영상처리 (Image Processing)
  
입출력이 영상인 모든 형태의 정보 처리  
목적하는 정보를 얻기 위해 영상 데이터를 취득하고 이를 가공, 처리, 해석하는 일련의 과정  
(디지털) 영상 처리(Digital Image Processing)  
디지털 영상을 처리하는 학문  
과거 현재
특수 목적으로 사용 일상적으로 사용

| 과거 | 현재 |
|------|---|
|특수 목적으로 사용 | 일상적으로 사용 |
|군사용, 공업용 | 엔터테인먼트, 디자인, 지문 인식, 얼굴 인식|
  
디지털 영상의 특성  
디지털 데이터 값이 명확하여 아날로그보다 안정적인 영상을 얻을 수 있음  
컴퓨터 기술이 발전하면 기술을 그대로 반영할 수 있음  
디지털 데이터 처리 방법을 활용할 수 있음  
안정적인 디지털 데이터 저장 장치에 영구적으로 저장할 수 있음  
복제 및 전송이 용이함  

디지털 영상 처리 기술의 분야
|기술 분야| 요약|
|------|---|
|디지털 영상 개선 |영상의 화질을 주관적으로 향상시키는 기술(밝기, 업스케일링: 인간에 눈에 좋게)|
|디지털 영상 복원 |손상된 영상을 원본 영상과 가깝게 복원시키는 기술(원본(정답)이 존재 객관적 향상|
|디지털 영상 변환 |디지털 영상을 다른 형태의 데이터로 변환하는 작업|
디지털 영상 분석 |디지털 영상으로부터 원하는 정보를 추출하는 작업|
|디지털 영상 압축|영상을 효율적으로 저장하고 전송하기 위해 불필요하거나 중복된 부분을 제거하는 작업|  
   
디지털 영상 개선   
영상의 화질을 주관적으로 향상시키는 기술  
밝기(0~255)  
x) 너무 어둡거나 밝은 영상 -> 명암 대비 조정  
어두운 곳은 더 어둡게, 밝은 곳은 더 밝게  
한쪽으로 몰려있던 히스토그램(분포)을 길게 늘림  
ex) 잡음(noise)이 많은 영상 -> 잡음 제거 알고리즘 사용  
까만, 하얀 점 잡음(소금, 후추 잡음 salt & pepper noise)  
잡음이 주변과 섞이게 평균을 적용(0검은색,255흰색을 평균으로)    
   
취득한 영상을 보기 좋은 화질로 변환하는 기술이므로, 결과물이 취득 당시의 실제 신호와 다를 수 있음  
객관적으로 원래 신호를 복원하는 기술? No. 이것은 영상 복원 기술  
휴먼 팩터를 고려하여(주관적으로) 좋은 화질로 변환하는 기술    
*휴먼 팩터(human factor): 상품, 시스템, 절차를 설계할 때 상호 작용하는 인간의 특성을 고려하는 설계와 방법론   

디지털 영상 복원(Restoration)  
손상된 영상을 원본 이미지로 되돌리는 것  
카메라 결함이나 저장/전송 실패 등으로 데이터가 훼손될 수 있음   
복원된 영상이 원본에 가까운 값을 가질수록 복원이 잘 된 영상임  
즉, 객관적인 화질 향상 기술  
객관적이므로(휴먼 팩터를 고려하지 않으므로) 주관적 화질 개선을 보장하진 않음  
데이터의 훼손 원인을 찾는 것이 중요함  
훼손 원인을 찾아 모델링한 뒤 역변환하는 방식을 사용할 수 있기 때문  
  
디지털 영상 변환(Transformation)  
 디지털 영상을 다른 형태의 데이터로 변환하는 작업  
 ex) Fourier 변환: [밝기, 색 성분의 강도] -> [주파수]   
푸리에 변환으로 주파수 감지, 발견한 주파수로 규칙적인 노이즈를 찾아 처리 -> 푸리에 역변환    
  
디지털 영상 분석(Analysis)  
디지털 영상으로부터 원하는 정보를 추출하는 작업  
|구조적 정보| 요약|
|------|---|
|디지털 영상의 구조를 파악하여 표현|디지털 영상의 특성을 수치화하여 표현|
|입력 영상에서 윤곽선을 추출하거나 영역을 분리함|입력 영상의 밝깃값 분포와 평균 값을 구함|
|인간이 직관적으로 이해할 수 있음|인간이 이해하기 어려움|  

   
디지털 영상 압축(Compression)  
효율적으로 저장/전송하기 위해 불필요하거나 중복된 부분을 제거하는 작업  
무손실 압축 기법과 손실 압축 기법으로 분류  
무손실 압축 기법: 압축한 뒤 다시 복원해도 복원 영상이 압축 이전의 원본 영상과 동일함  
손실 압축 기법: 압축한 뒤 다시 복원하면 원본 영상과 다름  
디지털 영상에서의 연산 - 덧셈 1 5 10 20 50 100  
우주 사진에는 기본적으로 noise(무작위, random noise, 더해서 상쇄)가 많이 있는데 같은 물체(같은 위치)를 여러 번 찍어 이미지를 더하면 개선할 수 있음  
  
디지털 영상에서의 연산 - 뺄셈   
두 이미지의 차이 확인 ->차이 극대화  
  
디지털 영상에서의 연산 - 곱셈  
원하는 부분만 보고 싶을 때(ROI(관심있는 영역 Region of Interest) mask를 씌운다.)    
   
디지털 영상에서의 연산 - 평균  
이미지를 뿌옇게 만듦.  
  
### 컴퓨터비전(Computer Vision)   
- 영상처리(Image Processing)  
정의: 영상을 가공하거나 보정하는 기술  
주요 기법: 노이즈 제거, 대비 조절, 색상 변환, 필터링 등  
응용: 의료 영상, 위성사진, 사진 보정  
  
- 컴퓨터비전(Computer Vision)  
정의: 인간의 시각을 흉내내는 컴퓨터 프로그램, 영상을 이해하고 판단하는 기술  
주요 기술: 분류(Classification), 검출(Detection), 분할(Segmentation), 추적(Tracking), 행동  
분석(Action Recognition)  
응용: 자율주행, 얼굴 인식, AR/VR, 스마트 팩토리
입력과 출력의 형태에 따른 학문 분야
| | 입력| | |
|------|----|----|----|
|출력 | |영상|심볼|
| |영상|저수준 영상처리|컴퓨터 그래픽|
| |심볼|고수준 영상처리, 컴퓨터 비전|자연어 처리|  

*심볼(Symbol): 영상이 아닌 다른 차원의 정보  
  
영상 -> 영상 : 이미지의 확대/축소  
영상 -> 심볼 : 차량 번호 인식   
심볼 -> 영상 : 코딩으로 애니메이션 생성  
심볼 -> 심볼(영상처리가 아님) : ChatGPT  
   
컴퓨터 비전은 인간의 시각을 흉내 내는 컴퓨터 프로그램
인공지능의 중요한 구성 요소가 됨(자율주행)  
(예) 시각 기능이 있는 로봇은 시각 기능이 없는 로봇보다 더 높은 성능을 보임  
현재 컴퓨터 비전 기술로 인간에 필적하는 시각 구현은 불가능하지만,
"과업을 한정하면" 인간 성능에 가깝거나 뛰어넘도록 활용할 수 있음  
=한가지 일만 시키면  
**응용 사례** 
1. 과일 수확 드론 2. 혈관 분할(CT촬영 조제) 3. 자율 주행 4. 불량 검사 5.선수 행동 분석 6. 고객 동선 분석 7. 얼굴 인식 보안 8. 태양광 모니터링 9. 게임 플레이(알파스타) 10. 지형 모니터링 11. 화성 탐사선 12. 광장 감시 13. 에드몽 벨라미(AI 생성 이미지) 14. 청소 로봇(SLAM: Simultaneous Localizaton And Mapping 3d 지도 맵핑) 15. 휴머노이드 로봇  
컴퓨터 비전이 어려운 이유는 명확함
시각, 시점 등에 따라 시시각각 변하는 물체의 모습
숫자로부터 물체를 인식해야 함
아직 약인공지능(<->강인공지능Strong AI, AGI Artificial General Intelligence)에 머물러있는 인공지능 기술

- 궁극적인 목표  
일반적인 상황에서 잘 작동하는 인간과 같은 시각 (강한 인공지능 AGI)  
영영 불가능하거나 먼 미래에 실현  
- 현실적인 목표  
제한된 환경에서 특정 과업을 높은 성능으로 달성 (약한 인공지능)  
컴퓨터 비전 문제를 여러 세부 문제로 구분하고 세부 문제별로 알고리즘 구상
문제들
분류(classification)  
검출(detection)  
분할(segmentation)  
추적(tracking)  
행동 분석(action analysis)  
### 컴퓨터 비전의 역사
신문 산업에서 태동한 디지털 영상  
1920년 유럽과 북미 간 케이블을 통해 사진 전송하는 Bartlane 시스템 개통  
1946년 세계 최초의 범용 전자식 컴퓨터인 에니악(ENIAC) 탄생  
빠른 계산이 주목적 (에니악은 초당 3000개 가량 덧셈)  
1957년 스캐너를 통해 디지털 영상을 컴퓨터에 저장  
5cmx5cm 사진에서 획득한 176x176 디지털 영상 -> 컴퓨터 비전의 태동  
  
----

## 3주차 OpenCV 실습
### 영상
인간의 눈: 동공 크기를 조절해 장단거리 조절, 인간의 눈엔 상에 맺혀 뉴런을 통해 전달된 걸 통해 이미지를 인식.  
카메라: 빛(밝기)과 색을 받아 센서에서 전기적인 신호로 받아들여 여러 칸으로 나눈 픽셀을 통해 받아들임    

디지털 영상의 획득
sampling: 칸을 얼마나 작게 가져올 것인가  
Quantization: 들어오는 밝기 값과 색상을 얼마나 잘게 가져올 것인가  
  
8페이지 그래프  
밝기 | 0 (검정)  
밝기 | 255 (흰색)  
그래프가 noise가 존재해서 흔들리게 보임  
sampling, Quantization 을 통해 noise 가 없는 경향성을 띄는 부분만 가지고 옴  
continuous → digitized 아날로그 디지털  

### Sampling과 Quantization
이미지를 몇 픽셀로 나타낼 것인가? = Sampling(샘플링)   
이미지의 밝기를 몇 단계로 표현할 것인가? = Quantization(양자화)    
- Sampling  
카메라 센서는 이미지를 격자 모양으로 잘라 저장함.  
얼마나 촘촘하게 자를 것인가를 결정하는 것이 샘플링.   
샘플링 간격이 좁을수록 고해상도 사진이 됨.  
- Quantization(양자화)  
각 픽셀의 색이나 밝기를 얼마나 다양하게 나타낼 것인가를 결정하는 것.   
예: 밝기 단위가 2단계 - 흑백만 있는 이진 이미지.  
밝기의 단계가 많을수록 자연스러운 이미지  
   
Sampling 간격이 좁으면 화질이 높아지고, Quantization level이 높아지면 여러가지 밝기를 표현할 수 있음  
  
컬러의 경우 (R, G, B) 3채널 값을 보여줄 때 겹쳐서 표현  

Quantization   
밝기 레벨의 수: L=2   
즉, 2, 4, 8, 16, ...   
(1레벨: 2가지 흑백 0 1)/(2레벨: 4가지 00 11 01 10)/(3단계: 8가지 001 010 100 011 110 111 000 101)...   
k =  1: binary image(이진), Dynamic range: [0,1]   
k =  8: grayscale image(회색조), Dynamic range: [0,255]    
k =  10: medical image(군사/의료용)   

### 컬러 이미지
Three Shot Color Filter Camera 5X7X3    
Color Mosaic Camera 5X7 이지만 교차시켜서 표현 용량이 작음  

문제   
1. 256개의 밝깃값을 나타내는 카메라에서 512*512 픽셀의 영상을 취득하면 용량은?  
(Three Shot Color Filter Camera인 경우만 생각한다.)  
  
512 * 512 * 8(256개 밝기값) * 3 (RGB 3채널)bit   
   
2. 256개의 밝깃값을 나타내는 카메라에서 512 * 512 픽셀의 30분 흑백(여러 단계가 있어도 흑백: 1레벨 의미 X) 동영상을 취득하면 용량은? 단, 동영상은 60fps이다.   
60(초당 60프레임) * 512 * 512 * 8(256개 밝기 값) * 30(분) * 60(초)  =  

### 영상입출력, 영상변환  

객체지향 특성과 강점  
- 객체는 능동적  
- '.'을 찍어 자신이 가진 함수를 능동적으로 호출할 수 있음.  
- 객체 내부에 있는 함수를 멤버 함수(member function), 또는 메서드(method)라 함.  
- 객체 내부에는 데이터를 저장할 멤버 변수(member variable)도 있음.  
- 필요한 만큼 얼마든지 찍어낼 수 있음  
  
실습
  
opencv 에서 B, G, R 순서  
imread
imwrite
cvtcolor
resize  
dsize  
출력된 이미지 크기 지정, 하라라도 0이면 fx,fy 인자를 비율로 사용함.   
fx = 가로 배율, fy = 세로 배율. 코드에선 1/4 크기가 됨.   

cvtColor 함수가 컬러 영상을 명암 영상으로 바꾸는 방법  
I = round(0.299 X R + 0.587 X G + 0.114 X B)  
109  
 
(실습)영상에 도형 그리고 글자 쓰기   
• OpenCV의 그래픽 기능   
• 영상에 글씨나 도형을 넣는데 유용   
• line(선), rectangle(사각형), polylines(점을 연결하는 선), circle(원), ellipse(타원), putText(글씨 삽입) 함수   
   
opencv (0, 0) (x, y)   
왼쪽 위가 (0,0)   
x는 오른쪽으로 y는 아래쪽으로   

----

## 4주차 영상 처리 
### 01 디지털 영상 02 이진 영상 03 점 연산, 영역 연산, 기하 연산
### cv 
cv 왼쪽 위 좌표 (0, 0)   
OpenCV에서 이미지는 numpy.ndarray 클래스로 표현됨  
그러므로 numpy.ndarray가 지원하는 다양한 함수를 사용할 수 있음   
(예) min, max, argmin, argmax, mean, sort, reshape, transpose, … …    
### 영상 종류  
명암 영상 2차원 텐서     
컬러 영상 3차원 텐서   
컬러 동영상 4차원 텐서 (t 시간 축)   
의료/군사 영상 (다분광/초분광/MR(MRI)/CT 영상) 고차원 텐서  
RGB-D 영상 4차원 텐서 (RGB + D) Depth 가 추가됨. 자율주행(급정거)같은 기술에서 사용  
점 구름 영상 라이다 (LiDAR: Light Detection and Ranging 빛 감지 후 거리 측정)로 획득 깊이 측정(자율주행)  

RGB(빛의 삼원색)  
혼합, RGB 큐브, 양자화된 RGB 큐브(양자화 단계에 따라 다양하게 표현가능)  
CMY( 프린트 색의 삼원색: Cyan, Magenta, Yellow : CMYK+ 검정(Key plate))   
HSV  
H(Hue): 색상, 색의 종류(빨, 파, 초 등)  
S(Saturation): 채도, 색의 선명한 정도(진하기)   
V(Value): 명암, 밝은 정도  
LAB  밝기(Lightness), 적록과 황청(a Channel, b Channel)   

### 이진 영상  
이진 영상(Binary image)  : 화소가 흑(0) 또는 백(1)인 영상  
- 컴퓨터 비전에서는 에지를 검출한 후 에지만 1로 표현하거나, 물체를 검출한 후 물체는 1, 배경은 0으로 표시하는 방식 등으로 이진 영상을 활용함   
- 이론적으로는 한 픽셀(화소)당 1bit면 되지만, 프로그램 편의상 한 픽셀당 1byte를 할당하는 경우가 많음  
ex)밝기값 T 이상일 때 검, 아래일 때 흰   
  
이진 영상을 만드려면 먼저 히스토그램을 획득해야 함  
흑과 백으로 나눌 기준점이 될 임계값 T를 구하고, 그 T보다 높으면 백(1), 낮으면 흑(0)으로 변환  
T값은 히스토그램이 계곡 모양으로 나타나는 부근으로 결정하면 좋음(두 영역이 잘 분리됨)  
T값을 구할 땐 Otsu 알고리즘이 유용함   
            1, f(j,1) >= T  
b(j, i) = {                 (3.1)  
            0, f(j,i) < T  
   
8가지 히스토그램 밝기 값 > 2**3 > 3bit  
계곡 모양 기준으로 나누므로 T = 4  
T 보다 크거나 같을 때 1, 작으면 0 으로 맵핑  
이진 이미지 변경 실습(일반/오츄 알고리즘)  
  
연결성(connectivity)  
: 픽셀들의 이웃과 연결된 영역을 판단하는 기준  
(예) 4-연결성(4-connectivity): 상하좌우 4개의 이웃만 연결된 것으로 간주함  
(예) 8-연결성(8-connectivity): 상하좌우+대각선까지 8개의 이웃이 연결된 것으로 간주함  
  
연결 요소(connected components)   
: 이진 영상에서 1의 값을 가진 연결된 화소의 집합  
즉, 하나의 연결된 물체(객체), 덩어리  
a - 원본  
b - 4연결성으로 찾아서 4개  
c - 8연결성으로 찾아서 3개  

   
모폴로지(morphology) 형태학, 형태 연산  
: 형태를 기반으로 이미지를 처리하는 이미지 처리 영산의 집합  
: 영상의 표현에 유용한 구조와 형태를 추출하는 연산들  
-> 이미지 분할(segmentation), 특징 추출(feature extraction) 등에 사용됨  
기본적으로 침식(Erosion)과 팽창(Dilation) 연산이 있음  
   
구조 요소(Structuring Element)   
: 모폴로지 연산에 사용되는 작은 마스크(커널) 형태의 패턴  
- 모폴로지 연산시 각 픽셀을 돌아다니며 어떻게 판단할지 정하는 기준이 되는 모양    
자유롭게 모양 설정 가능(연결요소와 다른점)  

팽창(dilation)  
: 영역을 키움.  
: 작은 홈을 메우거나 끊어진 영역을 연결하는 효과.(사소한 부분 덮기)  
침식(erosion)  
: 영역을 작게 만듦  
: 경계에 솟은 돌출 부분을 깎아내는 효과.(사소한 부분 지우기)  
열림(opening)  
: 원래 영역 크기를 유지  
: 침식 후 팽창  
닫힘(closing)  
: 원래 영역 크기를 유지  
: 팽창 후 침식  

팽창(dilation)  
dXd 의 사각형 A  
structuring element(d/4 X d/4인 사각형 B)  
팽창 시 d/8 만큼 늘어남  
dXd 의 사각형 A  
structuring element(d/4 X d 인 사각형 B)  
팽창 시 가로 면 d/8 만큼, 세로 면 d/2 만큼 늘어남  

팽창의 예시 - 지워진 글씨 인식률 높이기 (4-연결성과 비슷한 모양으로 연산 시 인식이 높아짐)  

침식(erosion)  
structuring element가 다 1인 경우를 남기고 지움  
dXd 의 사각형 A  
structuring element(d/4 X d/4인 사각형 B)  
침식 시 d/8 만큼 줄어듬   
dXd 의 사각형 A  
SE(structuring element)(d/4 X d 인 사각형 B)  
침식 시 가로 d/8 만큼 줄고, 기준 점만 남음    

SE가 커질수록 더 굵은 선을 제거함  
노이즈 제거(크기가 작을 때)  

연습문제1 축소에선 남아나는 게 없음  
지문을 처리할 때 팽창과 침식 모두 진행함  
-Opening: Erosion -> Dilation 침식, 팽창  
-Closing: Dilation -> Erosion 팽창, 침  
이미지 크기가 많이 바뀌지 않게 함  

-----

모폴로지 실습   

## 5주차 점연산 , 영역연산 , 기하연산

결과 이미지의 화소 값을 결정할 때, 무엇으로부터 그 값을 결정하느냐에 따라 가지로 구분됨   

- 점 연산(point operation)  
: 결과 이미지의 화소 값이 원본 영상의 같은 위치의 픽셀 하나만 참조하여 결정됨  
(예) 밝기 조정, 색상 반전 등 
영역 연산(area operation)  
: 결과 화소 값이 원본 이미지의 주변 이웃 화소들값들로부터도 결정됨  
(예)블러, 샤프닝, 에지 검출, 합성곱(CNN) 등  
기하 연산(geometric operation)  
: 결과 화소 값이 원본 이미지의 좌표를 변환해서 결정됨  
(예) 이미지 확대/축소, 뒤집기, 회전 등  

### 점 연산 - 밝기 조정  
감마 보정(Gamma correction)  
: 대표적인 밝기 보정 연산  
: 인간의 눈의 특성을 반영하여 밝기를 보정함  
히스토그램 평활화(Histogram equalization)  
: 히스토그램을 평평한 형태가 되도록 밝기값을 재분포시키는 방법  
: 명암 대비가 커짐  
: 즉, 어두운 이미지는 더 밝고 선명해지고, 전체적으로 너무 밝은 이미지는 디테일이 살아남  

실습   
결과  
감마 보정(Gamma correction)  
: 대표적인 밝기 보정 연산  
: 인간의 눈의 특성을 반영하여 밝기를 보정함  
히스토그램 평활화(Histogram equalization)  
: 히스토그램을 평평한 형태가 되도록 밝기값을 재분포시키는 방법  
: 명암 대비가 커짐  
: 즉, 어두운 이미지는 더 밝고 선명해지고, 전체적으로 너무 밝은 이미지는 디테일이 살아남  

영역 연산 - 컨볼루션  
• 영역 연산: 이웃 화소를 같이 고려해 새로운 값을 결정함  
• 주로 컨볼루션 연산을 통해 이루어짐  
컨볼루션 연산 적용시 이미지의 크기가 줄어드는 것을 방지하기 위해, padding을 적용함  
- zero padding: 필요한만큼 이미지의 가장자리를 확장한 후 0으로 채움  
- copy padding: 필요한만큼 이미지의 가장자리를 확장한 후 가장자리와 같은 화소값으로 채움  
  
### 영역 연산 - 다양한 필터  
Sharpening filter(윤곽 뚜렷하게)  
- 가운데를 강하게 주변의 영향력을 낮춤
  
Smoothing filter(이미지 부드럽게)  
- Averaging filter(각 필터의 모든 값을 동일하게 줄여줌, 가우시안 분포를 따르지않지만 비슷한 형태도 존재), 가우시안필터 사용 (가운데가 가장 높게, 퍼지면서 낮은 값)   
커널의 크기(필터 마스크)의 크기가 클수록 주변과 많이 겹쳐서 주변과 비슷해지며 이미지가 더 흐려짐(중심 픽셀의 영향력이 줄어들기 때문) 주변이 까매짐-제로 패딩  
제로(0-밝기, 검정)  
가우시안 필터-표준편차를 낮춤
잡음 제거 특화(장점)-물체의 경계가 흐려짐(단점)  

엠보싱 필터  
필터와 컨볼루션 연산을 통해 각 화소값이 0보다 작거나 255보다 크게 바뀌는 경우가 생길 수 있음.
• 이때 0 미만은 0으로, 255 초과는 255로 변환되기에 이미지의 데이터 손실이 발생함  
• 연산 결과가 범위를 벗어나게 되면 clip 함수, rescale 함수 등을 활용해 처리할 수 있음  

### 기하 연산 - 동차 좌표와 동차 행렬 
기하 연산 - 영상 확대/축소, 회전, 이동 등  
동차 좌표(homogeneous coordinate)  
• 2차원 좌표에 1을 추가해 3차원 벡터로 표현한 것  
• 3개 요소에 같은 w값을 곱하면 같은 점을 나타내는 것임  
(예) (-2,4,1)과 (-4,8,2)는 (-2,4)에 해당 (0, 3, 3) = (0, 1, 1)   
  
동차 행렬(homogeneous matrix)  
• 동차 좌표를 변환할 때 사용하는 행렬  
• 이동, 회전, 스케일링 등을 모두 3*3 행렬로 나타낼 수 있음  
• 동차 행렬을 동차 좌표에 곱하면 이동된 좌표가 계산됨  
어파인 변환(Affine Transformation)  
• 길이, 각도, 면적은 변할 수 있지만, 비율과 평행성(평행하는 것은 변환 후에도 평행)은 유지되는 기하 변환  
• (예) 평행 이동, 회전, 크기 변환, 전단(shear, 기울이기 직사각형->평행사변형)  
3가지 기하 변환  
|기하 변환| 동차 행렬| 설명 |
|------|----|----|
|이동 | |x 방향으로 tx, y 방향으로 ty만큼 이동|
|회전||원점을 중심으로 반시계 방향으로 만큼 회전|
|크기||x 방향으로 sx, y방향으로 sy 만큼 크기 조정(1보다 크면 확대, 1보다 작으면 축소| 
  
이동 행렬 곱샘    
(1 0 10)  
(0 1 15)   
(0 0 1)  
원래의 점 (1, 2, 1)  
곱한 값:(1 + 10, 2 +15, 1) -> (11, 17, 1)   
   
크기 변환 행렬 곱샘   
X방향 3배 , y방향 2배   
(1, 2, 1) -> (3, 4, 1)   
(3 0 0)  .  1  
(0 2 0) X  2  = (3, 4, 1)  
(0 0 1)  .  1   
  
1. 점 (1, 2, 1) 크기 변환 X: 3배, Y: 2배 크기변환 후    
2. 2.X 방향 +10, Y 방향 + 15만큼 이동하는 반환 적용  
3. 행렬 X (1.행렬 X 점)  
121 300 020 001 3, 4, 1 33, 64, 1  
가로  X  세로  = A 행렬   
1 0 10    3 0 0   3 0 10  
0 1 15    0 2 0   0 2 15  
0 0 1     0 0 1   0 0 1
A 행렬 X 점 (1, 2, 1) = (13, 19, 1)   

기하 연산 - 동차 좌표와 동차 행렬  
• 정사각형을 x 방향으로 2, y 방향으로 -1만큼 이동한 다음 반시계 방향으로 30도 회전(0,0중심에서)    
기하 연산 - 보간(사이 간 보충: Interpolation)  
• 영상 보간(interpolation)  
: 이미지나 영상에서 픽셀 사이의 값을 추정해 채워 넣는 과정  
- 최근접 이웃 보간(Nearest Neighbor Interpolation)  
: 가장 가까운 픽셀 값을 그대로 복사해서 사용함  
: 속도가 빠르지만, 계단 현상(aliasing)이 생길 수 있음  
- 양선형 보간(Bilinear Interpolation)  
: 주변 4개의 픽셀 값을 선형적으로 가중 평균해 새 픽셀 값을 계산함  
: 화질이 부드러워지지만 계산량이 늘어남  
- 스플인, 고차 보간 등(Spline, Bicubic Interpolation 등)  
: 주변의 더 많은 픽셀을 사용해 곡선 형태로 값을 추정함  
: 화질이 가장 좋지만, 계산이 매우 복잡함(복잡)  

실습  

### 에지와 영역  
에지 검출 알고리즘   
경계(에지) - 밝기 값이 급변하는 경우  
물체 내부 - 명암이 서서히 변함  
 미분: 어떤 함수의 순간 변화율을 구하는 것  
• (예) 독립변수 x에 대한 f(x)의 순간 변화율  
미분: 변수 x가 미하게 증가했을 때 함수 변화량을 측정하는 수학 기법  
미분을 디지털 영상에 적용하면, -> 최소단위: 픽셀  
  
실제 영상에서의 구현은 필터 u로 컨볼루션 (u를 에지 연산자라 부름)  
필터 u =뒤의 값 - 앞의 값  
실제 영상에서는 명암 변화가 한 화소에서 급격히 일어나는 것이 아니라, 여러 화소에 걸쳐 서서히 명암 변화가 발생하는 경향을 보임   
  
1차 미분(first derivative): 밝기가 얼마나 급격히 변하는가 (실제로는 에지가 여러 픽셀에 걸쳐 나타나 있으므로 1차 미분된 값으로는 에지의 위치를 찾기 어려움)  
미분
ramp(경사로, 서서히 밝기가 변함) 부분에의 값을 알 수 없음   
2차 미분(second derivative): 밝기의 변화 속도가 얼마나 급격히 변하는가(가속도)  
=다음 픽셀 값 + 이전 픽셀 값 - (2 X 현재 픽셀 값)  
zero crossing 영교차 (양수 - 음수 사이 0) 을 엣지라 판단 할 수 있다.  
### 1차 미분에 기반한 에지 연산자
실제 영상에 있는 잡음을 흡수하기 위해 크기가 2인 필터를 크기 3으로 확장  
1차원을 2차원으로 확장  
- Ux 가로 Uy 세로  
프로윗 연산자  
소벨 연산자(가까운 4-연결에 2배로 강하게 연산)   
Sobel Filter  
• 필터를 통해 에지 방향을 판단하려면 에지 강도와 그래디언트 방향이 필요함  
• 에지 강도(edge strength): 에지일 가능성을 나타내는 수치(확률)  
• 그래디언트 방향(gradient): 이미지에서 밝기가 가장 빠르게 증가하는 방향, 에지의 진행 방향  
• 에지 방향(edge direction): 그래디언트 방향 + 90도
  
에지 강도: s(y,x)  
그레디언트 방향: d(y, x)  
arctan = 아크 탄젠트: 탄젠트의 역함수  
  - 문제 풀어보기) 음영 처리된 점에 소벨 필터를 적용해 에지의 강도와 방향 구하기.
  - 점 s(3, 4)  
  - 소벨 필터 Ux 부터 적용  
  - f'x = 3 + 3 -2 +6 -1 + 3 = 6 (필터와 원래 있던 값을 곱한다음에 더함)
  - f'y =  -3 -6 -3 +1 + 2 + 6 = -6  
  - 에지 강도 = 식에 따라서 루트 72 -> 8.4852...   
  - 그레디언트 방향 = arctan(-1) = -45도  
  - 에지 방향 = 그래디언트 방향 + 90도 = 45도  
  - 그래프에서 실선 빨간색이 그레디언트 방향, 에지방향이 빨간 점선
밝기 변화 검출
주로, 수평 방향과 수직 방향으로 미분함 -> Sobel X filter, Sobel Y filter  
Sobel X filter (Horizontal direction)  
Sobel Y filter (Vertical direction)
Sobel X filter 적용: 수평 방향으로 이동하면서 변화가 큰 것을 검출. 즉, 수직 방향의 edge가 잘 보임(코)  
Sobel Y filter 적용: 수직 방향으로 이동하면서 변화가 큰 것을 검출. 즉, 수평 방향의 edge가 잘 보임(입술)  
## 06주차 캐니에지
### Canny Edge Detector
캐니 에지 검출기 설계시 idea  
Low error rate  
: 가짜 에지를 찾는 비율이 낮아야 한다.  
Edge points should be well localized  
: 검출한 에지가 true edge와 최대한 가까워야 한다  
Single edge point response  
: 에지가 하나가 있는 곳에서는 에지 하나만을 찾아야 한다.  
주요 단계들  
1. Noise reduction(노이즈 감소)
2. Gradient calculation(그래디언트 계산)
3. Edge Strength and Orientation(에지 강도와 방향 계산)
4. Non-maximum Suppression(비최대 억제)
5. Double Thresholding(이중 임계값)
6. Edge Tracking(에지 연결)

1. Noise reduction(노이즈 감소)
: 입력 이미지에 Gaussian filter를 적용해 노이즈를 감소시킴
- 더 정확한 에지 검출을 수행할 수 있음

2. Gradient calculation (그래디언트 계산)
  
3. Edge Strength and Orientation(에지 강도와 방향 계산)  
: 노이즈가 제거된 이미지에서 Sobel 필터를 사용하여 그래디언트의 크기와 방향을 계산.  
- 이미지에서 경사도가 가장 급격한 부분을 찾을 수 있음
  
4. Non-maximum Suppression(비최대 억제)   
: 에지의 강도와 방향 정보를 사용하여 non-maximum suppression 수행함  
주변의(local neighborhood) 에지 픽셀들 중에서 가장 강한 에지만을 선택하고, 나머지 에지를 억제함.  
결과로 얇고 정확한 에지를 얻음  

5. Double Thresholding(이중 임계값)  
: 검출한 에지 픽셀들을 강한 에지 | 약한 에지 | 노이즈로 분류하기 위해 이중 임계값을 적용함.  
강한 에지 = 확실한 에지  
약한 에지 = 에지 후보군(추가 검토를 위해 보류)  
잡음 = 에지가 아니므로 제거함  

6. Edge Tracking(에지 연결)  
: 약한 에지 중에서 강한 에지와 연결되는 픽셀을 찾아 에지를 형성함  
에지로 형성되지 않은 나머지 약한 에지들을 잡음으로 간주하여 제거함   

결과를 확인해보면 다른 edge detector 와 달리 약한 밝기여도 연결선이 있으면 살려둠  

#### 경계선 찾기
• 8-connectivity로 에지 픽셀들을 서로 연결해 경계선(contour)을 구성할 수 있음(대각선 포함)  
• OpenCV에서는 findContours 함수로 이를 구현함  
#### 허프 변환(Hough Transform)  
• 이미지에서 직선, 원, 곡선 등 특정 형태를 찾는 알고리즘  
• 캐니 에지 검출을 통해 검출한 에지 픽셀들을 대상으로 해당 픽셀들이 찾고자 하는 특정 형태에 속하는지 수학적인 투표(voting) 방식을 통해 찾아냄  
• 캐니 에지 검출의 에지 끊어짐 문제 등을 해결하고 원하는 형태를 robust하게 찾아주는 알고리즘    
 전체 에지 중 일부만이 찾고자하는 형태이고, 나머지는 노이즈나 이상치일 때 원하는 형태를 찾기 어려울 수 있음  
- 이유: 에지 픽셀마다 모든 가능한 형태에 대해 투표하므로 이상치나 노이즈인 부분도 그 형태로 검출되기도 하기 때문  
찾고자 하는 도형의 파라미터가 많아질수록, 계산량과 메모리 사용이 급증함  
끊어진 에지나 부분적인 직선에서는 검출이 잘 되지 않음  

#### RANSAC
• 허프 변환의 한계를 보완하기 위해 고안된 알고리즘  
• RANSAC(RANdom SAmple Consensus)  
• 전체 데이터 중 일부만이 진짜 직선이고, 나머지는 노이즈나 이상치일 때, 검출하고자 하는 형태를 잘 찾음  
• 잡음이나 이상치에도 불구하고, 무작위로 뽑은 샘플로부터 가장 많은 데이터가 동의하는(합의하는) 모델을 찾아내는 알고리즘  
### 영역 분할
• 영역 분할(Region Segmentation)  
: 물체가 점유한 영역을 구분하는 작업  
• 전통적 영상처리 알고리즘을 통해 색이 비슷한 영역으로 나눌 수도 있으며, 인공지능을 활용해 의미가 같은 영역별로 구분할 수 있음  
• 에지 검출 알고리즘의 결과는 폐곡선을 형성하지 못하는 경우가 많아서, 곡선이 잘 연결되게 처리해야 영역 분할을 할 수 있음  
#### 워터셰드 알고리즘
• 워터셰드 알고리즘(Watershed Algorithm)
• 픽셀의 밝기를 높이로 간주하여 지형이라고 생각함
• 이후, 골짜기 부분에 물을 채워가며 영역을 나눔
• 물이 만나는 경계선을 찾아 영역을 분할함
#### • 슈퍼픽셀(superpixel)
: 이미지에서 색상, 밝기 등 비슷한 특성을 가진 픽셀들을 모아 하나의 덩어리로 그룹화한 것.
• 슈퍼픽셀로 나누면 수십만개의 픽셀을 수백-수천개의 슈퍼픽셀로 줄여서 이미지 처리 속도를
높이고, 사람의 인지 방식과 더 비슷하게 이미지를 다룰 수 있음  
   
SLIC(Simple Linear Iterative Clustering)   
• 슈퍼픽셀을 만드는 대표적인 알고리즘  
• 먼저 이미지를 격자로 나누고, 영역의 중심에서 주변 픽셀들의 색상과 위치를 기준으로 반복적으로 클러스터링해서 슈퍼픽셀을 만듦  
• 경계의 정확도가 높으며, 크기가 일정한 슈퍼픽셀을 빠르게 생성할 수 있음   

1. 군집 중심이 우연히 에지에 놓이는 일을 방지하기 위해 3*3 이웃 중에서 그래디언트가 가장 낮은 이웃 화소로 이동시킴.  
2. 각 픽셀들의 색상값과 위치값을 고려해 어느 군집 중심에 속하게 할지 결정함  
3. 할당 후, 클러스터에 속한 픽셀들의 위치 평균값으로 슈퍼픽셀의 중심점을 다시 계산함  
4. 픽셀 할당과 중심 재계산을 반복해가면서 클러스터의 중심이 더이상 크게 변하지 않을 때까지 진행함  
5. 최종적으로 경계선이 슈퍼픽셀의 외곽으로 결정됨

실습   
한계  
• 지역적 명암 변화만 고려함  
- 그래서 물체의 색이 배경색과 비슷하면 경계가 형성되지 않아 배경과 섞이게 됨  
-> 전역적 정보도 함께 사용하는 알고리즘으로 개선 필요  

정규화 절단 알고리즘(Normalized Cut Algorithm)  
• 이미지 전체를 고려함   
• 슈퍼픽셀을 노드로 하고, 관련성을 에지 가중치로 두어 이미지 전체를 하나의 그래프로 두며 연산하는 이미지 분할 알고리즘  
• 비슷한 부분은 연결되어 있도록, 차이가 많이 나는 부분은 나뉘어지도록 분할함  

### 대화식 분할(Interactive Segmentation)
: 사용자가 초기에 일부 정보를 제공해서 컴퓨터가 객체와 배경을 더 정확하게 구분하도록 돕는 이미지 분할 방법  

#### Active Contour(Snake) 알고리즘
: 사용자가 객체의 대략적인 윤곽선을 그려주면, 컴퓨터가 그 선을 자동으로 객체의 실제 경계선에 맞게 움직여서(수축/팽창) 최종 윤곽선을 찾아주는 방법  
1. 2. 3. 사용자가 객체 주변에 곡선을 그려 초기화  
곡선이 이미지의 색상 변화가 큰 부분을 따라가도록 곡선을 점진적으로 이동시킴(꿈틀꿈틀)  
곡선이 더이상 크게 움직이지 않으면 객체의 경계선으로 결정함  

#### GrabCut 알고리즘
: 사용자가 지정한 영역을 바탕으로 이미지에서 객체와 배경을 자동으로 분리하는 대화식 이미지 분할 방법  
1. 2. 3. 4. 5. 사용자가 붓으로 물체와 배경을 초기 지정함(사각형 등으로 지정할 수도 있음)  
붓칠된 화소를 기준으로 물체와 배경의 히스토그램을 생성함  
색칠되지 않은 나머지 화소들은 두 히스토그램과의 유사성으로 배경/전경에 속할 확률을 추정함  
확률 정보를 이용해 영역을 갱신함  
위 과정을 계속 반복하다 결과가 거의 바뀌지 않게 되는 시점에 계산을 마침  

### 영역 특징
(실습) 이진 영역 특징 추출 함수 사용하기

## 7주차 지역 특징
### 대응점 문제(correspondence problem)
: 서로 다른 영상에서 같은 물체의 같은 지점을 찾아내는 문제  
• 컴퓨터 비전의 거의 모든 응용에서 핵심 과제가 됨  
• (예) 파노라마 영상 제작, 물체 인식, 물체 추적, 스테레오 비전, 카메라 캘리브레이션 등 대응점 문제
• 대응점 문제를 제대로 해결하지 못하면, 여러 영상 간 정합이 틀어지거나 인식과 추적의 정확도가 크게 떨어짐  
• 기존의 에지와 영역 기반 특징으로부터 대응점 문제를 해결하지 어려웠음  
• 이유: 조명 변화, 노이즈, 물체의 회전, 크기변경에 성능이 좋지 않음  
• 해결책: 지역 특징(Local Feature) 개념의 도입  
• (예) SIFT, SURF, ORB, BRISK, AKAZE 등  
물체 추적 문제  
0.5초 간격의 영상들  
• 물체(버스)를 추적하려면 대응점 문제를 풀어야 함  
• 녹색 박스처럼 좁은 지역들을 보고 특징점 여부 결정함  
• 반복성(repeatability): 같은 물체의 같은 부분이 다른 영상에서도 계속 같은 특징점으로 잡히는 능력  
• 반복성을 중요하게 취급하는 알고리즘을 수행할 수 있음  
지역 특징(Local Feature)  
: 이미지의 일부분(작은 패치)에서 추출되는 특징으로, 다른 영상에서도 동일한 지점을 안정적으로 대응시킬 수 있는 특징점을 뜻함  
- 유용한 지역 특징이 되려면 여러 조건을 만족해야 함  
조건: 반복성, 불변성, 분별력, 지역성, 적당한 양, 계산 효율  
지역 특징의 조건  
• 반복성(Repeatability)  
• 같은 물체가 서로 다른 두 영상에 나타났을 때 첫 번째 영상에서 검출된 특징점이 두 번째 영상에서도 같은 위치에서 높은 확률로 검출되어야 함  
• 불변성(Invariance)  
• 물체에 이동, 회전, 스케일, 조명 변환이 일어나도 특징 기술자(descriptor)의 값은 비슷해야 함  
• 분별력(Discriminative power)  
• 물체의 다른 곳에서 추출된 특징과 두드러지게 달라야 함. 분별력이 낮으면 물체의 다른 곳에서 추출된 특징과 엉뚱한 곳이 매칭될 위험이 있음  
지역 특징의 조건
지역성(Locality)  
• 작은 영역을 중심으로 특징 벡터를 추출해야 물체를 가리는 현상(Occlusion)이 발생해도 매칭이 안정적으로 동작함
적당한 양
• 특징점이 더 많으면 더 정확하게 추적할 수 있으나, 과하게 많으면 계산 시간이 오래 걸림  
• 계산 효율  
• 경기 중계시 실시간으로 추적해야 하는 프로그램 등, 실시간으로 작동해야 하는 프로그램이 많으므로 계산 효율이 높아야 함  
대응점 찾기 인지 실험  
#### 모라벡 알고리즘(Moravec Algorithm)
(idea) 주변 방향으로 조금만 이동시켜도 픽셀 값이 급격히 변하는 점이 특징점이다  
모라벡 알고리즘의 원리(간단하게)  
1. 영상의 모든 픽셀을 하나씩 검사함  
2. 각 픽셀 주변(예: 3×3 또는 5×5 영역)을 잡음  
3. 그 영역을 상하좌우, 대각선 방향으로 조금씩 이동시켜봄  
4. 이동했을 때 밝기 변화(픽셀 값 차이)가 가장 큰 값을 측정함  
5. 그 값이 크면 코너(특징점), 작으면 균일한 부분(특징 없음) 으로 판단함  
밋밋한 영역 - 이동해도 거의 변하지 않음 -> 특징점 아님  
에지 부분 - 한 방향으로만 변함 -> 불안정  
코너(모서리) - 어느 방향으로 이동해도 픽셀 값이 급격히 변함 -> 특징점으로 선정  
이동과 회전 불변한 지역 특징  
### 불변(invariant)
• 불변(invariant): 어떤 변화가 일어나도 결과가 달라지지 않는다.  
• 즉, 입력 영상이 회전되거나, 이동되거나, 크기가 바뀌어도 특징점을 같은 것으로 인식할 수 있다면 불변한다고 할 수 있음  
• 이동 불변(Translation invariance)  
: 같은 물체의 위치가 사진상 옮겨져도, 특징점은 여전히 특징점으로 검출됨  
• 회전 불변(Rotation Invariance)  
: 사진을 회전해도, 특징점은 여전히 특징점으로 검출됨  
• 크기 불변(Scale Invariance)  
: 사진을 확대/축소해도, 특징점은 여전히 특징점으로 검출됨  
#### 해리스 코너 검출(Harris Corner Detection)  
• 모라벡 알고리즘(Moravec Algorithm)은 단순히 움직이면 픽셀 값이 많이 변하는 곳을 특징점으로 잡는 아이디어로 시작함  
• 그러나, 물체가 회전하거나, 조명이 바뀌거나, 노이즈가 있으면 잘 작동하지 않음  
• 해리스 코너 검출 알고리즘은 모라벡 알고리즘의 단점을 보완한 알고리즘!  
• 영역 정의  
• Flat region(평탄한 영역) - 모든 방향으로 변화가 거의 없음 (하늘, 벽 등)  
• Edge(에지) - 한 방향으로는 변화하지만 다른 방향으로는 일정함 (물체의 경계선)  
• Corner(코너) - 모든 방향으로 변화가 큼 (창문의 모서리, 건물의 꼭짓점)  
• 즉, 코너는 움직였을 때 어는 방향으로든 값이 많이 변하는 지점!  
해리스 코너 검출(Harris Corner Detection)  
• 해리스 알고리즘은 각 픽셀마다 코너 응답값(Corner Response, R)을 계산함  
• R값은 해당 픽셀이 코너일 가능성을 나타내는 지표.  
• 이 R값을 맵으로 표현할 수 있음 = 즉, 픽셀마다 코너일 가능성을 밝깃값으로 표시해주는 맵  
• R값이 큰 점들 중 국소 최대값만 코너로 선택함  
• 평탄한 영역 - R값이 0과 가까움 -> 특징이 없음  
• 에지 영역 - R값이 0보다 작음 -> 한 방향으로만 변화함  
• 코너 영역 - R값이 0보다 큼 -> 모든 방향으로 크게 변화함  
해리스 코너 검출(Harris Corner Detection)  
• 해리스 코너 알고리즘은 이동과 회전에 불변이며, 스케일에는 불변이 아님  
  
### 스케일 불변한 지역 특징
Scale Space  
• 사람의 시각은 본능적으로 스케일 불변이지만, 컴퓨터에게는 그렇지 않음  
• 그래서 컴퓨터에게는 단 하나의 영상을 보여주는 대신, 마치 멀리서 본 것처럼 흐리게 만든 영상을 여러 장 함께 보여주는 방법을 사용함  
• 스케일 공간(Scale Space): 입력 영상 한 장에서 여러 거리에서 본 듯한 영상을 여러 장 인위적으로 만들어내는 방법  
• 스케일 공간을 만드는 대표적인 두 가지 방법 - 가우시안 스무딩 방법, 피라미드 방법   
#### 가우시안 스무딩 방법(Gaussian Smoothing Method)
• 원본 영상의 크기는 그대로 두고, 가우시안 필터에서 흐림 정도를 바꿔가며 여러 흐릿한 영상을 만들어내는 방법  
• σ(시그마)를 작게 하면 → 조금만 흐려짐 (가까이서 본 느낌)  
• σ를 크게 하면 → 많이 흐려짐 (멀리서 본 느낌)  
• σ값을 연속적으로 조절할 수 있음  
|σ 값| 영상| 느낌|  
|------|----|----|
|σ = 1 |선명함| 가까이서 본 듯|  
|σ = 3 |약간 흐림| 중간 거리|  
|σ = 8 |많이 흐림| 멀리서 본 듯|  

피라미드 방법(Pyramid Method)  
• 영상의 크기 자체를 줄여가며 여러 단계의 작은 영상을 만드는 방법  
• 원본 영상(너비와 폭)을 ½, ¼, ⅛ 크기로 점점 축소  
• 각 단계(레벨)를 “한 스케일”로 간주   
• 여러 단계를 쌓아올리면 영상 피라미드(Image Pyramid) 가 됨  
• 영상의 크기가 줄어들어 계산이 빨라지지만, 스케일 변화가 이산적임(discrete)  
  
|면적| 설명|
|----|----|
|원본 (100%)| 가까이서 본 영상|
|50% |절반 크기(가로 세로 절반)|
|25% |더 멀리서 본 것처럼|
  
#### SIFT(Scale-Invariant Feature Transform)
• 영상 속에서 스케일(크기), 회전, 조명 변화에도 영향을 받지 않는 강력한 특징점(feature point)을 찾아내고, 각 특징점을 벡터로 표현하는 알고리즘  
• SIFT 알고리즘 단계들  
1. 스케일 공간(Scale-space) 생성  
2. DoG(Difference of Gaussian) 피라미드 생성  
3. 3D 극값(Extrema) 검출 - 키포인트(특징점) 후보 찾기  
4. 키포인트 정제(Refinement) & 엣지 응답 제거로 안정된 키포인트만 남김  
5. 방향 할당(Orientation Assignment)하여 회전 불변하게 만들기  
6. 기술자(Descriptor) 생성 - 128차원 벡터  
7. 매칭(Matching)  
   
1단계: 스케일 공간(Scale-Space) 생성  
• 같은 물체가 멀리/가까이 있어도 같은 특징으로 인식하게 하기 위해 한 이미지에서 멀리서 본 듯한 버전을 여러 개 만들어야 함  
• 가우시안 블러에 다양한 σ(시그마) 값을 적용해 가우시안 피라미드를 생성함  
• Octave(옥타브): 해상도를 절반으로 줄일 때마다 1단계씩 이동함   
• Interval(인터벌, 간격): 한 옥타브 내에서 σ값을 점진적으로 증가시킨 **여러 레벨**  
• 1단계를 거친 결과값:  
• (옥타브의 수)*(옥타브당 인터벌 수 +3:출력 결과를 맞춰주기 위해서 더했음.)장의 가우시안 블러 영상  
  
2단계: DoG(Difference of Gaussian) 피라미드 생성  
• 극값을 뽑기 위한 "변화 강조 지도"가 필요함  
• 인접한 두 스케일의 가우시안 영상의 차이를 구해 DoG 영상을 구함  
• 2단계를 거친 결과값:  
• 옥타브마다 (옥타브당 인터벌수+2)장의 DoG 영상을 생성함  
  
3단계: 3D 극값(Extrema) 검출 - 키포인트(특징점) 후보 찾기  
• 영상에서 한 점이 주변보다 현저히 밝거나 어두운 값을 가질 때, 그 점을 극대값(Maximum), 또는 극소값(Minimum)으로 부르며, 이러한 점들을 극값이라 부름  
• 가장 두드러진 지점만 후보로 삼아 이후에 이 지점에서 계산을 진행함  
• DoG 피라미드의 각 픽셀을 3차원에서 주변 26개 이웃과 비교함(3*3*3큐브)  
• 현재 값이 이웃 전부보다 크거나 전부보다 작으면 극값(extrema)으로 취급함  
• 임계값을 적용해 너무 차이가 작은 지점은 버림  
• 3단계를 거친 결과값:  
• 키포인트 후보의 위치 리스트  
  
4단계: 키포인트 정제(Refinement) & 엣지 응답 제거로 안정된 키포인트만 남김  
• 극값 중 잡음이나 엣지로 부터 생긴 취약한 후보를 제거하는 과정  
• 서브픽셀 정제: 키포인트의 위치와 스케일을 더 정확히 계산함. 대비가 너무 낮은 점은 제거함  
• 엣지 응답 제거: 한 방향에서만 크게 변하는 엣지 부분은 분별력이 낮으므로 제거함  
• 4단계를 거친 결과값:  
• 정제된 키포인트의 위치  
  
5단계: 방향 할당(Orientation Assignment)하여 회전 불변하게 만들기  
• 회전 불변을 만들기 위해, 키포인트마다 "대표 방향"을 부여함   
• 이미지를 회전해도 키포인트 좌표계는 스스로 돌려서 같은 기준으로 만들어 비교하게 함   
• 키포인트 주변에서 σ값에 비례한 반경의 영역에서 기울기와 크기, 방향을 계산함  
• **최대 빈도**인 방향을 **대표 방향**으로 설정함  
• 최대 빈도에 근접한 다른 방향이 있으면, 보조 방향을 가진 추가적인 키포인트도 생성함  
• 5단계를 거친 결과값:  
• 최종 키포인트  
  
6단계: 기술자(Descriptor) 생성 - 128차원 벡터  
• 다른 이미지의 키포인트와 서로 비교하기 위해 숫자 벡터로 표현하는 과정  
• 좌표계를 키포인트의 대표 방향으로 회전함 -> 회전 불변성을 확보하기 위함  
• 가우시안 가중을 적용해 히스토그램을 누적함(중심부일수록 가중치를 크게 부여하기 위해)  
• 기울기의 방향을 고려한 128차원 벡터를 만들고 정규화함  
• 임계값보다 작은 곳을 잘라낸 후 다시 정규화함(좁은 영역의 조명과 노이즈에 더 강인해짐)  
• 6단계를 거친 결과값:  
• 각 키포인트마다 128차원의 실수 벡터(SIFT Descriptor)  
각 키포인트 주변의 16 * 16 픽셀 영역을 4 * 4 픽셀의 블록으로 나누고
• 각 블록에서 8방향의 기울기 히스토그램을 계산함  
-> 즉, 4*4*8=128차원 벡터가 생성됨  
  
• 7단계: 매칭(Matching)  
• 두 이미지에서 같은 물체의 같은 부분을 서로 연결함  
• 한 이미지의 각 키포인트 벡터와 다른 이미지의 모든 벡터 간 거리를 계산함  
• 가장 가까운 이웃과 두번째로 가까운 이웃의 거리 비율을 확인함   
• 그들의 비율이 (주로) 0.75보다 작을 경우, 신뢰할만한 매칭으로 채택함  
• 7단계를 거친 결과값:  
• 신뢰할만한 매칭 쌍 목록  
(sift 실습)  
응용  
SIFT를 응용한 특징점 검출 알고리즘들  
• SURF(Speeded-Up Robust Features)  
• FAST(Features from Accelerated Segment Test)  
• AGAST(Adaptive and Generic Accelerated Segment Test)  
• ORB(Oriented FAST and Rotated BRIEF)  

### 특징점 매칭
• 매칭이 어려운 이유  
• 영상의 특징점이 너무 많음  
• 두 영상에서 수백개~수천개의 특징점이 있으므로 가능한 쌍은 수십만개가 됨  
• 기술자(Descriptor)에 잡음 요소가 있음  
• 조명, 가림(Occlusion), 블러 등의 현상으로 벡터값이 일정하지 않음  
• 배경/시점 차이  
• 실제로 대응하지 않는 점들도 우연히 비슷하게 보여 매칭되어버릴 수 있음  

최근접 이웃 매칭(Nearest Neighbor Matching) 전략  
• 두 영상 A, B에서 각각의 특징점 들 a1,a2,..., b1, b2,...들이 있을 때 비슷한 특징점들을 서로 매칭해야 함  
• 최근접 이웃 매칭에서는 A 영상의 각 특징점들에 대해 B 영상의 모든 특징점과의 거리를 계산함  
• NN1, 1st nearest neighbor: 가장 가까운 특징점 1개  
• NN2, 2nd nearest neighbor: 그 다음으로 가까운 특징점   
  
최근접 이웃 거리 거리 비율 매칭(Nearest Neighbor Distance Ratio Matching) 전략  
• 단순히 가장 가까운 특징점 하나만 선택하면 엉뚱하게 매칭되는 경우가 많음  
• 이런 경우를 방지하기 위해 가까운 정도를 비교하는 비율을 이용함  
• d1 : 첫 번째로 가까운 거리  
• d2 : 두 번째로 가까운 거리  
• T: 비율 임계값 (보통 0.75 사용)  
• NN1이 NN2보다 확실히 더 가까워야 진짜 매칭으로 인정함  

거리 비율(Ratio Test) 매칭
T = 0.75 일 때,  

후보 거리 설명
NN1 0.42 첫 번째로 가까움
NN2 0.53 두 번째로 가까움
비율      0.79     (-> 매칭 안됨. 임계값보다 큼.  )

후보 거리 설명
NN1 0.32 첫 번째로 가까움
NN2 0.62 두 번째로 가까움
비율        (0.52, 매칭  )

매칭 성능 측정  
혼동 행렬  
예측 긍/부  
정답 긍/부  

ROC(Receiver Operating Characteristic) 곡선과 AUC(Area Under Curve)  
• 좋은 알고리즘일수록 거짓 긍정률(FPR, False Positive Rate)은 낮고, 참 긍정률(TPR, True Positive Rate)은 높게 나타남  
• 최근접 거리 비율 매칭 식에서 T값을 작게 하면 거짓 긍정률이 작아짐  
• T가 커지면 거짓 긍정률이 커지는 대신 참 긍정률도 따라 커지는 경향을 보임  
• 적절한 T값을 찾아야 함   
T값을 바꾸며 생기는 TPR과 FPR의 변화를 그래프로 나타낸 것이 ROC 곡선이며, 그 전체 성능을 수치로 나타낸 것이 AUC임.  
• AUC가 높을수록 매칭 알고리즘의 성능이 좋음  
(실습)  

### 호모그래피(Homography)
• 두 평면(plane) 사이의 좌표 변환 관계를 나타내는 3*3 행렬(변환행렬)  
• 즉, 한 평면을 다른 평면으로 투영(projection)하는 변환식  
• 호모그래피 추정(Homography Estimation)  
• 두 영상 사이에서 대응점(매칭점)을 이용해 호모그래피 행렬 H를 계산하는 과정  
• 호모그래피 추정이 필요한 이유  
• 시점에 따라 이미지가 어긋남  
• 대응점만으로 이미지를 매칭하기에 불안정함  
• 영상의 특정 점만 맞추는 것이 아니라, 영상 전체를 변환하는 행렬이 필요함  
• 응용  
• 파노라마 사진 만들기 - 두 장의 사진을 하나로 이어 붙이려면 하나의 이미지를 뒤틀어 기존 사진과 맞게 정렬해야 함. 그때 H행렬을 이용함  
• 증강현실(AR) - 실제 영상 위에 2D 객체를 올릴 때, 카메라 시점에 맞게 올려두어야 함  
(실습) 호모그래피 추정  



















































































































































































































































